{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"1. Data_wrangling.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"v5RBcKjImHCO","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import os\n","import joblib"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X_NTHeslFFr7","colab_type":"code","outputId":"2740b5bc-78ae-4b7e-8826-f46219c65bc4","executionInfo":{"status":"ok","timestamp":1571410712204,"user_tz":-60,"elapsed":23980,"user":{"displayName":"Gareth Egerton","photoUrl":"","userId":"13594124457560643670"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["# mount google drive if running in colab\n","try:\n","  from google.colab import drive\n","  drive.mount('/content/drive/')\n","  import sys\n","  sys.path.append('/content/drive/My Drive/Colab Notebooks/Starbucks_Udacity/src/utilities')\n","  %cd /content/drive/My Drive/Colab Notebooks/Starbucks_Udacity/notebooks/exploratory\n","except:\n","  pass"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n","/content/drive/My Drive/Colab Notebooks/Starbucks_Udacity/notebooks/exploratory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HXZIYpP2FRRv","colab_type":"code","colab":{}},"source":["import helper"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mMfvScY2U7Dh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"4af4538c-697b-4809-8455-980a2fc45d1d","executionInfo":{"status":"ok","timestamp":1571410722554,"user_tz":-60,"elapsed":440,"user":{"displayName":"Gareth Egerton","photoUrl":"","userId":"13594124457560643670"}}},"source":["helper.pull()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["\n","  !git config --global user.email 'gareth.egerton@gmail.com'\n","  !git config --global use.name 'GarethEgerton'\n","  !git clone https://GarethEgerton:P400dellpc@github.com/GarethEgerton/Starbucks_Udacity.git\n","  !git pull --rebase origin master\n","  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ISKSXfX0aBOi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"0d25675e-c11c-45f6-8f62-1794d2d88f7d","executionInfo":{"status":"ok","timestamp":1571411608218,"user_tz":-60,"elapsed":3030,"user":{"displayName":"Gareth Egerton","photoUrl":"","userId":"13594124457560643670"}}},"source":["  !git config --global user.email 'gareth.egerton@gmail.com'\n","  !git config --global use.name 'GarethEgerton'\n","  #!git clone https://GarethEgerton:P400dellpc@github.com/GarethEgerton/Starbucks_Udacity.git\n","  !git pull --rebase origin master"],"execution_count":15,"outputs":[{"output_type":"stream","text":["error: cannot pull with rebase: You have unstaged changes.\n","error: please commit or stash them.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9ytMH9CJXTeL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"2677b200-6ba8-459c-c09d-90419b1cf0a2","executionInfo":{"status":"ok","timestamp":1571410724598,"user_tz":-60,"elapsed":306,"user":{"displayName":"Gareth Egerton","photoUrl":"","userId":"13594124457560643670"}}},"source":["helper.push()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["\n","  !git add --all\n","  !git commit -m message\n","  !git push origin master\n","  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CYVnCTwSakSg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"7faf90df-ec2e-46d1-fba0-c92f0ef763b2","executionInfo":{"status":"ok","timestamp":1571411351232,"user_tz":-60,"elapsed":1193,"user":{"displayName":"Gareth Egerton","photoUrl":"","userId":"13594124457560643670"}}},"source":["!git status"],"execution_count":10,"outputs":[{"output_type":"stream","text":["On branch master\n","Your branch is up to date with 'origin/master'.\n","\n","Changes not staged for commit:\n","  (use \"git add/rm <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mmodified:   1. Data_wrangling.ipynb\u001b[m\n","\t\u001b[31mdeleted:    Starbucks_Udacity\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TG26TiSJaPie","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"bf5518b2-3e9b-44a1-bfe2-bd6cfd094044","executionInfo":{"status":"ok","timestamp":1571411623771,"user_tz":-60,"elapsed":5720,"user":{"displayName":"Gareth Egerton","photoUrl":"","userId":"13594124457560643670"}}},"source":["  !git add --all\n","  !git commit -m message\n","  !git push origin master\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[master 8cc50c5] message\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite notebooks/exploratory/1. Data_wrangling.ipynb (86%)\n","Counting objects: 5, done.\n","Delta compression using up to 2 threads.\n","Compressing objects: 100% (5/5), done.\n","Writing objects: 100% (5/5), 693 bytes | 346.00 KiB/s, done.\n","Total 5 (delta 3), reused 0 (delta 0)\n","remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n","To https://github.com/GarethEgerton/Starbucks_Udacity.git\n","   fa1c714..8cc50c5  master -> master\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gBazhdH_mHCW","colab_type":"code","colab":{}},"source":["portfolio = pd.read_json('../../data/raw/portfolio.json', orient='records', lines=True)\n","profile = pd.read_json('../../data/raw/profile.json', orient='records', lines=True)\n","transcript = pd.read_json('../../data/raw/transcript.json', orient='records', lines=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QaU7TIk-mHCY","colab_type":"text"},"source":["## 1. Examining and reorganising portfolio data"]},{"cell_type":"code","metadata":{"id":"oc255vQlmHCY","colab_type":"code","colab":{}},"source":["portfolio.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MUu3XxatmHCc","colab_type":"code","colab":{}},"source":["# input dataframe and column names to return unique items per column\n","def uniques(df, column_names):\n","    for col in df[column_names].columns:\n","        unique_values = list(sorted(df[col].unique(), reverse=True))\n","        print(\"{}: {}\".format(col, unique_values, len(unique_values)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fr6bfpZBmHCe","colab_type":"code","colab":{}},"source":["uniques(portfolio, ['difficulty', 'duration', 'offer_type', 'reward'])\n","print(\"channel: '[email, mobile, social, web]'\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NA1bxRwbmHCg","colab_type":"code","colab":{}},"source":["# Converting channels into categories, dropping email since this is common to all channels\n","portw = portfolio.join(portfolio.channels.str.join('|').str.get_dummies())\n","portw.drop(['channels', 'email'], axis=1, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PeY-xWi7mHCj","colab_type":"code","colab":{}},"source":["# Changing column order \n","portw = portw[['id', 'difficulty', 'reward', 'duration', 'offer_type', 'mobile', 'web', 'social']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pvr8fsFjmHCl","colab_type":"code","colab":{}},"source":["# Get dummies for offer_type and removing original column\n","portw = portw.join(pd.get_dummies(portw.offer_type))\n","portw.drop(['offer_type'], axis=1, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p7aYSPgHmHCn","colab_type":"code","colab":{}},"source":["# Sorting according to expected effect of offer\n","portw.sort_values(['difficulty', 'reward', 'duration'], ascending=False, inplace=True)\n","portw"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tYjaWei_mHCq","colab_type":"code","colab":{}},"source":["# mapping offer id to simpler format\n","id = list(portw['id'])\n","portw.id = portw.id.map({a:b for a,b in zip(id, 'abcdefghij')})\n","portw.reset_index(drop=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1dUXj7gmmHCs","colab_type":"text"},"source":["* ### Script to wrangle raw portfolio data"]},{"cell_type":"code","metadata":{"id":"UCE6BingmHCs","colab_type":"code","colab":{}},"source":["def wrangle_portfolio(portfolio, save=None):\n","    '''\n","    Wrangle and preprocess portfolio data into usable format\n","    '''\n","        \n","    portw = portfolio.join(portfolio.channels.str.join('|').str.get_dummies())\n","    portw.drop(['channels', 'email'], axis=1, inplace=True)\n","    portw = portw[['id', 'difficulty', 'reward', 'duration', 'offer_type', 'mobile', 'web', 'social']]\n","    portw = portw.join(pd.get_dummies(portw.offer_type))\n","    portw.drop(['offer_type'], axis=1, inplace=True)\n","    portw.sort_values(['difficulty', 'reward', 'duration'], ascending=False, inplace=True)\n","    id = list(portw['id'])\n","    portw.id = portw.id.map({a:b for a,b in zip(id, 'abcdefghij')})\n","    portw.reset_index(drop=True, inplace=True)\n","    \n","    if save:\n","        try:\n","            dirName='../../data/interim'\n","            os.mkdir(dirName)\n","            print(\"Directory \" , dirName ,  \" Created \") \n","        except FileExistsError:\n","            pass\n","        \n","        portw.to_csv(dirName + '/portw1.csv', index=False)\n","        print('saved as {}'.format(dirName + '/portw1.csv'))\n","    \n","    return portw"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"spgfcC5ImHCu","colab_type":"code","colab":{}},"source":["wrangle_portfolio(portfolio, save=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3ItW3frumHCx","colab_type":"text"},"source":["## 2. Examining and reorganising profile and transcript data"]},{"cell_type":"code","metadata":{"id":"PnnNsir1mHCx","colab_type":"code","colab":{}},"source":["profile.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J06lhBdvmHC0","colab_type":"code","colab":{}},"source":["# getting dummies for gender, unknown \"None\" becomes baseline\n","profilec = profile.join(pd.get_dummies(profile.gender))\n","profilec.drop(['gender'], axis=1, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dLljuvtZmHC2","colab_type":"code","colab":{}},"source":["# converting to datetime\n","profilec.became_member_on = pd.to_datetime(profilec.became_member_on, format='%Y%m%d')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H5nLVbuKmHC4","colab_type":"code","colab":{}},"source":["# rearranging column order\n","profilec = profilec[['id', 'age', 'income', 'became_member_on', 'F', 'M', 'O']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-XiQonFxmHC6","colab_type":"code","colab":{}},"source":["# renaming id column to person\n","profilec.rename(columns={'id': 'person'}, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jgqkpW4umHC8","colab_type":"code","colab":{}},"source":["profilec.head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XY6aRIMUmHC_","colab_type":"code","colab":{}},"source":["# merging trancript data with person data\n","tranc = transcript.merge(profilec, on='person')\n","tranc.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-i6qVBtJmHDD","colab_type":"code","colab":{}},"source":["# Splitting out value column into two columns\n","tranc = tranc.join(pd.DataFrame(list(tranc.value)))\n","tranc.drop('value', axis=1, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ckjg6cBxmHDG","colab_type":"code","colab":{}},"source":["tranc.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k1QjQAQJmHDI","colab_type":"code","colab":{}},"source":["# filling NaNs as blank strings across two column version of offer id\n","tranc['offer id'] = tranc['offer id'].fillna(value=\"\")\n","tranc['offer_id'] = tranc['offer_id'].fillna(value=\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"so_456ZEmHDJ","colab_type":"code","colab":{}},"source":["# concatenating offer id fields since raw data had differing naming conventions\n","tranc['offer_id'] = tranc['offer id'].map(str) + tranc.offer_id.map(str)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xpwjVcC_mHDL","colab_type":"code","colab":{}},"source":["# remove redundant offer id column\n","tranc.drop('offer id', axis=1, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pdZDqrAamHDN","colab_type":"code","colab":{}},"source":["tranc.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ud8wh7XmmHDT","colab_type":"code","colab":{}},"source":["# mapping offer_id to abcdefghij representing each offer\n","tranc.offer_id = tranc.offer_id.map({a:b for a,b in zip(id, 'abcdefghij')})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NcWX-431mHDU","colab_type":"code","colab":{}},"source":["# renaming columns to more appropriate column titles\n","tranc.rename(columns={'offer_id': 'id', 'reward': 'rewarded', 'became_member_on': 'signed_up'}, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ywKSZvqmHDW","colab_type":"code","colab":{}},"source":["tranc.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bd1Z2V_mmHDY","colab_type":"code","colab":{}},"source":["# merging tranc with portw\n","tranc = tranc.merge(portw, how='left', on='id')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0vf0c-yxmHDa","colab_type":"code","colab":{}},"source":["tranc.head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"curoyn0AmHDe","colab_type":"code","colab":{}},"source":["# Filling all NaNs as zeros\n","tranc = tranc.fillna(value=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eza-9cOAmHDh","colab_type":"code","colab":{}},"source":["# Replacing zero income back to NaN - XGBoost algorithm will be able to handle nans\n","tranc.income.replace({0: np.nan}, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pm3Kt1FgmHDi","colab_type":"code","colab":{}},"source":["# Age of 118 is likely an error where birthdate has been set to 1900, therefore replace age of 119 with Nan\n","tranc.age.replace({118: np.nan}, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BBGBDYIOmHDk","colab_type":"code","colab":{}},"source":["tranc.head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PBcJ2oXVmHDm","colab_type":"code","colab":{}},"source":["# Adding cumulative amount spent\n","tranc['cum_amount'] = tranc.groupby('person').amount.cumsum()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bVZJXH29mHDo","colab_type":"code","colab":{}},"source":["tranc.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SsmrbYj1mHDr","colab_type":"code","colab":{}},"source":["# Converting event into categorical data type\n","tranc.event = pd.Categorical(tranc.event, categories=['offer received', 'offer viewed', 'offer completed', 'transaction'], ordered=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CeHLbsklmHDs","colab_type":"code","colab":{}},"source":["# concatenating person with offer id to try and make a unique offer_id \n","tranc['offer_id'] = tranc.person + tranc.id.astype(str)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bvlODI1WmHDu","colab_type":"code","colab":{}},"source":["# reordering columns\n","tranc = tranc[['offer_id', 'person', 'event', 'time', 'age', 'income', 'signed_up', 'F', 'M', 'O',\n","               'amount', 'id', 'rewarded', 'difficulty', 'reward', 'duration', 'mobile', 'web', \n","               'social', 'bogo', 'discount', 'informational', 'cum_amount']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Rahyf_cmHDx","colab_type":"code","colab":{}},"source":["# concatenating offer_id with offer type to find instaces of multiple similar offers\n","tranc['offer_multi'] = tranc.offer_id + tranc.event.astype(str)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1zM2XfVwmHDy","colab_type":"code","colab":{}},"source":["# checking value counts for offer_multi containing string \"offer\" - confirmed that multiple offers of the same type can be applied to same customer\n","tranc['offer_multi'].value_counts()[tranc['offer_multi'].value_counts().index.str.contains('offer')].head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgNJH47KmHD0","colab_type":"code","colab":{}},"source":["# Adding a numerical suffix to distinigush a repeated similar offer for the same person\n","tranc['offer_multi_correction'] = tranc.groupby('offer_multi').offer_id.apply(lambda n: n + (np.arange(len(n))+1).astype(str))\n","\n","'''\n","Utilising:\n","https://stackoverflow.com/questions/27806825/how-to-modify-duplicated-rows-in-python-pandas\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AOyDtcKamHD2","colab_type":"code","colab":{}},"source":["# updating offer_id to new unique version\n","tranc.offer_id = tranc.offer_multi_correction"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RXuLWzHQmHD4","colab_type":"code","colab":{}},"source":["# dropping unneeded columns\n","tranc.drop(['offer_multi', 'offer_multi_correction'], axis=1, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EEGkCsO0mHD7","colab_type":"code","colab":{}},"source":["# creating joined column as number of days difference from latest signed up date in the data\n","tranc['joined'] = (tranc.signed_up - tranc.signed_up.max()).dt.days"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zz-MO1bAmHD9","colab_type":"code","colab":{}},"source":["tranc.head(100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YctU8xIemHEA","colab_type":"code","colab":{}},"source":["# one hot encoding event\n","tranc = tranc.join(pd.get_dummies(tranc.event))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-SHST1KwmHEB","colab_type":"code","colab":{}},"source":["# converting id to categorical \n","tranc['id'] = pd.Categorical(tranc.id, categories=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', '0'], ordered=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"odQM1GnrmHED","colab_type":"code","colab":{}},"source":["tranc.head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x0EPlrgumHEG","colab_type":"text"},"source":["* ### Script to wrangle raw profile and transcript data"]},{"cell_type":"code","metadata":{"id":"Bk6bnQgtmHEG","colab_type":"code","colab":{}},"source":["def wrangle_portfolio(portfolio, profile, transcript, save=None):\n","    '''\n","    Wrangle and preprocess profile and transcript data into usable format\n","    '''\n","    \n","    portw = portfolio.join(portfolio.channels.str.join('|').str.get_dummies())\n","    portw.drop(['channels', 'email'], axis=1, inplace=True)\n","    portw = portw[['id', 'difficulty', 'reward', 'duration', 'offer_type', 'mobile', 'web', 'social']]\n","    portw = portw.join(pd.get_dummies(portw.offer_type))\n","    portw.drop(['offer_type'], axis=1, inplace=True)\n","    portw.sort_values(['difficulty', 'reward', 'duration'], ascending=False, inplace=True)\n","    id = list(portw['id'])\n","    portw.id = portw.id.map({a:b for a,b in zip(id, 'abcdefghij')})\n","    portw.reset_index(drop=True, inplace=True)\n","    \n","    if save:\n","        try:\n","            dirName='../../data/interim'\n","            os.mkdir(dirName)\n","            print(\"Directory \" , dirName ,  \" Created \") \n","        except FileExistsError:\n","            pass\n","        \n","        portw.to_csv(dirName + '/portw.csv', index=False)\n","        print('saved as {}'.format(dirName + '/portw.csv'))\n","    \n","    \n","    profilec = profile.join(pd.get_dummies(profile.gender))\n","    profilec.drop(['gender'], axis=1, inplace=True)\n","    profilec.became_member_on = pd.to_datetime(profilec.became_member_on, format='%Y%m%d')\n","    profilec = profilec[['id', 'age', 'income', 'became_member_on', 'F', 'M', 'O']]\n","    profilec.rename(columns={'id': 'person'}, inplace=True)\n","    \n","    tranc = transcript.merge(profilec, on='person')\n","    tranc = tranc.join(pd.DataFrame(list(tranc.value)))\n","    tranc.drop('value', axis=1, inplace=True)\n","    \n","    tranc['offer id'] = tranc['offer id'].fillna(value=\"\")\n","    tranc['offer_id'] = tranc['offer_id'].fillna(value=\"\")\n","    \n","    tranc['offer_id'] = tranc['offer id'].map(str) + tranc.offer_id.map(str)\n","    tranc.drop('offer id', axis=1, inplace=True)\n","    \n","    tranc.offer_id = tranc.offer_id.map({a:b for a,b in zip(id, 'abcdefghij')})\n","    tranc.rename(columns={'offer_id': 'id', 'reward': 'rewarded', 'became_member_on': 'signed_up'}, inplace=True)\n","    tranc = tranc.merge(portw, how='left', on='id')\n","    tranc = tranc.fillna(value=0)\n","    tranc.income.replace({0: np.nan}, inplace=True)\n","    tranc.age.replace({118: np.nan}, inplace=True)\n","    tranc['cum_amount'] = tranc.groupby('person').amount.cumsum()\n","    tranc.event = pd.Categorical(tranc.event, categories=['offer received', 'offer viewed', 'offer completed', 'transaction'], ordered=True)\n","    tranc['offer_id'] = tranc.person + tranc.id.astype(str)\n","    tranc = tranc[['offer_id', 'person', 'event', 'time', 'age', 'income', 'signed_up', 'F', 'M', 'O',\n","               'amount', 'id', 'rewarded', 'difficulty', 'reward', 'duration', 'mobile', 'web', \n","               'social', 'bogo', 'discount', 'informational', 'cum_amount']]\n","    tranc['offer_multi'] = tranc.offer_id + tranc.event.astype(str)\n","    tranc['offer_multi_correction'] = tranc.groupby('offer_multi').offer_id.apply(lambda n: n + (np.arange(len(n))+1).astype(str))\n","    tranc.offer_id = tranc.offer_multi_correction\n","    tranc.drop(['offer_multi', 'offer_multi_correction'], axis=1, inplace=True)\n","    tranc['joined'] = (tranc.signed_up - tranc.signed_up.max()).dt.days\n","    tranc = tranc.join(pd.get_dummies(tranc.event))\n","    tranc['id'] = pd.Categorical(tranc.id, categories=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', '0'], ordered=True)\n","    \n","    if save:\n","        try:\n","            dirName='../../data/interim'\n","            os.mkdir(dirName)\n","            print(\"Directory \" , dirName ,  \" Created \") \n","        except FileExistsError:\n","            pass\n","        \n","        #tranc.to_csv(dirName + '/tranc.csv', index=False)\n","        #tranc.to_pickle(dirName + '/tranc.pickle')\n","        #print('saved as {}'.format(dirName + '/tranc.pickle'))\n","        \n","        joblib.dump(tranc, dirName + '/' + save, compress=True)\n","        print('saved as {}'.format(dirName + '/' + save)) \n","    \n","    return tranc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qCzUCbxqmHEI","colab_type":"code","colab":{}},"source":["tranc = wrangle_portfolio(portfolio, profile, transcript, save='tranc.joblib')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aHSSX7domHEJ","colab_type":"code","colab":{}},"source":["tranc"],"execution_count":0,"outputs":[]}]}