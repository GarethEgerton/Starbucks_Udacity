{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23980,
     "status": "ok",
     "timestamp": 1571410712204,
     "user": {
      "displayName": "Gareth Egerton",
      "photoUrl": "",
      "userId": "13594124457560643670"
     },
     "user_tz": -60
    },
    "id": "X_NTHeslFFr7",
    "outputId": "2740b5bc-78ae-4b7e-8826-f46219c65bc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n",
      "/content/drive/My Drive/Colab Notebooks/Starbucks_Udacity/notebooks/exploratory\n"
     ]
    }
   ],
   "source": [
    "# mount google drive if running in colab\n",
    "try:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive/')\n",
    "  import sys\n",
    "  sys.path.append('/content/drive/My Drive/Colab Notebooks/Starbucks_Udacity/src/utilities')\n",
    "  %cd /content/drive/My Drive/Colab Notebooks/Starbucks_Udacity/notebooks/exploratory\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gBazhdH_mHCW"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "portfolio = pd.read_json('../../data/raw/portfolio.json', orient='records', lines=True)\n",
    "profile = pd.read_json('../../data/raw/profile.json', orient='records', lines=True)\n",
    "transcript = pd.read_json('../../data/raw/transcript.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QaU7TIk-mHCY"
   },
   "source": [
    "## 1. Examining and reorganising portfolio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oc255vQlmHCY"
   },
   "outputs": [],
   "source": [
    "portfolio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MUu3XxatmHCc"
   },
   "outputs": [],
   "source": [
    "# input dataframe and column names to return unique items per column\n",
    "def uniques(df, column_names):\n",
    "    for col in df[column_names].columns:\n",
    "        unique_values = list(sorted(df[col].unique(), reverse=True))\n",
    "        print(\"{}: {}\".format(col, unique_values, len(unique_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fr6bfpZBmHCe"
   },
   "outputs": [],
   "source": [
    "uniques(portfolio, ['difficulty', 'duration', 'offer_type', 'reward'])\n",
    "print(\"channel: '[email, mobile, social, web]'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NA1bxRwbmHCg"
   },
   "outputs": [],
   "source": [
    "# Converting channels into categories, dropping email since this is common to all channels\n",
    "portw = portfolio.join(portfolio.channels.str.join('|').str.get_dummies())\n",
    "portw.drop(['channels', 'email'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PeY-xWi7mHCj"
   },
   "outputs": [],
   "source": [
    "# Changing column order \n",
    "portw = portw[['id', 'difficulty', 'reward', 'duration', 'offer_type', 'mobile', 'web', 'social']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pvr8fsFjmHCl"
   },
   "outputs": [],
   "source": [
    "# Get dummies for offer_type and removing original column\n",
    "portw = portw.join(pd.get_dummies(portw.offer_type))\n",
    "portw.drop(['offer_type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7aYSPgHmHCn"
   },
   "outputs": [],
   "source": [
    "# Sorting according to expected effect of offer\n",
    "portw.sort_values(['difficulty', 'reward', 'duration'], ascending=False, inplace=True)\n",
    "portw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYjaWei_mHCq"
   },
   "outputs": [],
   "source": [
    "# mapping offer id to simpler format\n",
    "id = list(portw['id'])\n",
    "portw.id = portw.id.map({a:b for a,b in zip(id, 'abcdefghij')})\n",
    "portw.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dUXj7gmmHCs"
   },
   "source": [
    "* ### Script to wrangle raw portfolio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UCE6BingmHCs"
   },
   "outputs": [],
   "source": [
    "def wrangle_portfolio(portfolio, save=None):\n",
    "    '''\n",
    "    Wrangle and preprocess portfolio data into usable format\n",
    "    '''\n",
    "        \n",
    "    portw = portfolio.join(portfolio.channels.str.join('|').str.get_dummies())\n",
    "    portw.drop(['channels', 'email'], axis=1, inplace=True)\n",
    "    portw = portw[['id', 'difficulty', 'reward', 'duration', 'offer_type', 'mobile', 'web', 'social']]\n",
    "    portw = portw.join(pd.get_dummies(portw.offer_type))\n",
    "    portw.drop(['offer_type'], axis=1, inplace=True)\n",
    "    portw.sort_values(['difficulty', 'reward', 'duration'], ascending=False, inplace=True)\n",
    "    id = list(portw['id'])\n",
    "    portw.id = portw.id.map({a:b for a,b in zip(id, 'abcdefghij')})\n",
    "    portw.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    if save:\n",
    "        try:\n",
    "            dirName='../../data/interim'\n",
    "            os.mkdir(dirName)\n",
    "            print(\"Directory \" , dirName ,  \" Created \") \n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        \n",
    "        portw.to_csv(dirName + '/portw1.csv', index=False)\n",
    "        print('saved as {}'.format(dirName + '/portw1.csv'))\n",
    "    \n",
    "    return portw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "spgfcC5ImHCu"
   },
   "outputs": [],
   "source": [
    "wrangle_portfolio(portfolio, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ItW3frumHCx"
   },
   "source": [
    "## 2. Examining and reorganising profile and transcript data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PnnNsir1mHCx"
   },
   "outputs": [],
   "source": [
    "profile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J06lhBdvmHC0"
   },
   "outputs": [],
   "source": [
    "# getting dummies for gender, unknown \"None\" becomes baseline\n",
    "profilec = profile.join(pd.get_dummies(profile.gender))\n",
    "profilec.drop(['gender'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dLljuvtZmHC2"
   },
   "outputs": [],
   "source": [
    "# converting to datetime\n",
    "profilec.became_member_on = pd.to_datetime(profilec.became_member_on, format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5nLVbuKmHC4"
   },
   "outputs": [],
   "source": [
    "# rearranging column order\n",
    "profilec = profilec[['id', 'age', 'income', 'became_member_on', 'F', 'M', 'O']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-XiQonFxmHC6"
   },
   "outputs": [],
   "source": [
    "# renaming id column to person\n",
    "profilec.rename(columns={'id': 'person'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jgqkpW4umHC8"
   },
   "outputs": [],
   "source": [
    "profilec.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XY6aRIMUmHC_"
   },
   "outputs": [],
   "source": [
    "# merging trancript data with person data\n",
    "tranc = transcript.merge(profilec, on='person')\n",
    "tranc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-i6qVBtJmHDD"
   },
   "outputs": [],
   "source": [
    "# Splitting out value column into two columns\n",
    "tranc = tranc.join(pd.DataFrame(list(tranc.value)))\n",
    "tranc.drop('value', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ckjg6cBxmHDG"
   },
   "outputs": [],
   "source": [
    "tranc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k1QjQAQJmHDI"
   },
   "outputs": [],
   "source": [
    "# filling NaNs as blank strings across two column version of offer id\n",
    "tranc['offer id'] = tranc['offer id'].fillna(value=\"\")\n",
    "tranc['offer_id'] = tranc['offer_id'].fillna(value=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "so_456ZEmHDJ"
   },
   "outputs": [],
   "source": [
    "# concatenating offer id fields since raw data had differing naming conventions\n",
    "tranc['offer_id'] = tranc['offer id'].map(str) + tranc.offer_id.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpwjVcC_mHDL"
   },
   "outputs": [],
   "source": [
    "# remove redundant offer id column\n",
    "tranc.drop('offer id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pdZDqrAamHDN"
   },
   "outputs": [],
   "source": [
    "tranc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ud8wh7XmmHDT"
   },
   "outputs": [],
   "source": [
    "# mapping offer_id to abcdefghij representing each offer\n",
    "tranc.offer_id = tranc.offer_id.map({a:b for a,b in zip(id, 'abcdefghij')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NcWX-431mHDU"
   },
   "outputs": [],
   "source": [
    "# renaming columns to more appropriate column titles\n",
    "tranc.rename(columns={'offer_id': 'id', 'reward': 'rewarded', 'became_member_on': 'signed_up'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ywKSZvqmHDW"
   },
   "outputs": [],
   "source": [
    "tranc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bd1Z2V_mmHDY"
   },
   "outputs": [],
   "source": [
    "# merging tranc with portw\n",
    "tranc = tranc.merge(portw, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0vf0c-yxmHDa"
   },
   "outputs": [],
   "source": [
    "tranc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "curoyn0AmHDe"
   },
   "outputs": [],
   "source": [
    "# Filling all NaNs as zeros\n",
    "tranc = tranc.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eza-9cOAmHDh"
   },
   "outputs": [],
   "source": [
    "# Replacing zero income back to NaN - XGBoost algorithm will be able to handle nans\n",
    "tranc.income.replace({0: np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pm3Kt1FgmHDi"
   },
   "outputs": [],
   "source": [
    "# Age of 118 is likely an error where birthdate has been set to 1900, therefore replace age of 119 with Nan\n",
    "tranc.age.replace({118: np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BBGBDYIOmHDk"
   },
   "outputs": [],
   "source": [
    "tranc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PBcJ2oXVmHDm"
   },
   "outputs": [],
   "source": [
    "# Adding cumulative amount spent\n",
    "tranc['cum_amount'] = tranc.groupby('person').amount.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bVZJXH29mHDo"
   },
   "outputs": [],
   "source": [
    "tranc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SsmrbYj1mHDr"
   },
   "outputs": [],
   "source": [
    "# Converting event into categorical data type\n",
    "tranc.event = pd.Categorical(tranc.event, categories=['offer received', 'offer viewed', 'offer completed', 'transaction'], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CeHLbsklmHDs"
   },
   "outputs": [],
   "source": [
    "# concatenating person with offer id to try and make a unique offer_id \n",
    "tranc['offer_id'] = tranc.person + tranc.id.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bvlODI1WmHDu"
   },
   "outputs": [],
   "source": [
    "# reordering columns\n",
    "tranc = tranc[['offer_id', 'person', 'event', 'time', 'age', 'income', 'signed_up', 'F', 'M', 'O',\n",
    "               'amount', 'id', 'rewarded', 'difficulty', 'reward', 'duration', 'mobile', 'web', \n",
    "               'social', 'bogo', 'discount', 'informational', 'cum_amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Rahyf_cmHDx"
   },
   "outputs": [],
   "source": [
    "# concatenating offer_id with offer type to find instaces of multiple similar offers\n",
    "tranc['offer_multi'] = tranc.offer_id + tranc.event.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1zM2XfVwmHDy"
   },
   "outputs": [],
   "source": [
    "# checking value counts for offer_multi containing string \"offer\" - confirmed that multiple offers of the same type can be applied to same customer\n",
    "tranc['offer_multi'].value_counts()[tranc['offer_multi'].value_counts().index.str.contains('offer')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sgNJH47KmHD0"
   },
   "outputs": [],
   "source": [
    "# Adding a numerical suffix to distinigush a repeated similar offer for the same person\n",
    "tranc['offer_multi_correction'] = tranc.groupby('offer_multi').offer_id.apply(lambda n: n + (np.arange(len(n))+1).astype(str))\n",
    "\n",
    "'''\n",
    "Utilising:\n",
    "https://stackoverflow.com/questions/27806825/how-to-modify-duplicated-rows-in-python-pandas\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AOyDtcKamHD2"
   },
   "outputs": [],
   "source": [
    "# updating offer_id to new unique version\n",
    "tranc.offer_id = tranc.offer_multi_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RXuLWzHQmHD4"
   },
   "outputs": [],
   "source": [
    "# dropping unneeded columns\n",
    "tranc.drop(['offer_multi', 'offer_multi_correction'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEGkCsO0mHD7"
   },
   "outputs": [],
   "source": [
    "# creating joined column as number of days difference from latest signed up date in the data\n",
    "tranc['joined'] = (tranc.signed_up - tranc.signed_up.max()).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zz-MO1bAmHD9"
   },
   "outputs": [],
   "source": [
    "tranc.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YctU8xIemHEA"
   },
   "outputs": [],
   "source": [
    "# one hot encoding event\n",
    "tranc = tranc.join(pd.get_dummies(tranc.event))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-SHST1KwmHEB"
   },
   "outputs": [],
   "source": [
    "# converting id to categorical \n",
    "tranc['id'] = pd.Categorical(tranc.id, categories=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', '0'], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "odQM1GnrmHED"
   },
   "outputs": [],
   "source": [
    "tranc.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x0EPlrgumHEG"
   },
   "source": [
    "* ### Script to wrangle raw profile and transcript data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bk6bnQgtmHEG"
   },
   "outputs": [],
   "source": [
    "def wrangle_portfolio(portfolio, profile, transcript, save=None):\n",
    "    '''\n",
    "    Wrangle and preprocess profile and transcript data into usable format\n",
    "    '''\n",
    "    \n",
    "    portw = portfolio.join(portfolio.channels.str.join('|').str.get_dummies())\n",
    "    portw.drop(['channels', 'email'], axis=1, inplace=True)\n",
    "    portw = portw[['id', 'difficulty', 'reward', 'duration', 'offer_type', 'mobile', 'web', 'social']]\n",
    "    portw = portw.join(pd.get_dummies(portw.offer_type))\n",
    "    portw.drop(['offer_type'], axis=1, inplace=True)\n",
    "    portw.sort_values(['difficulty', 'reward', 'duration'], ascending=False, inplace=True)\n",
    "    id = list(portw['id'])\n",
    "    portw.id = portw.id.map({a:b for a,b in zip(id, 'abcdefghij')})\n",
    "    portw.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    if save:\n",
    "        try:\n",
    "            dirName='../../data/interim'\n",
    "            os.mkdir(dirName)\n",
    "            print(\"Directory \" , dirName ,  \" Created \") \n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        \n",
    "        portw.to_csv(dirName + '/portw.csv', index=False)\n",
    "        print('saved as {}'.format(dirName + '/portw.csv'))\n",
    "    \n",
    "    \n",
    "    profilec = profile.join(pd.get_dummies(profile.gender))\n",
    "    profilec.drop(['gender'], axis=1, inplace=True)\n",
    "    profilec.became_member_on = pd.to_datetime(profilec.became_member_on, format='%Y%m%d')\n",
    "    profilec = profilec[['id', 'age', 'income', 'became_member_on', 'F', 'M', 'O']]\n",
    "    profilec.rename(columns={'id': 'person'}, inplace=True)\n",
    "    \n",
    "    tranc = transcript.merge(profilec, on='person')\n",
    "    tranc = tranc.join(pd.DataFrame(list(tranc.value)))\n",
    "    tranc.drop('value', axis=1, inplace=True)\n",
    "    \n",
    "    tranc['offer id'] = tranc['offer id'].fillna(value=\"\")\n",
    "    tranc['offer_id'] = tranc['offer_id'].fillna(value=\"\")\n",
    "    \n",
    "    tranc['offer_id'] = tranc['offer id'].map(str) + tranc.offer_id.map(str)\n",
    "    tranc.drop('offer id', axis=1, inplace=True)\n",
    "    \n",
    "    tranc.offer_id = tranc.offer_id.map({a:b for a,b in zip(id, 'abcdefghij')})\n",
    "    tranc.rename(columns={'offer_id': 'id', 'reward': 'rewarded', 'became_member_on': 'signed_up'}, inplace=True)\n",
    "    tranc = tranc.merge(portw, how='left', on='id')\n",
    "    tranc = tranc.fillna(value=0)\n",
    "    tranc.income.replace({0: np.nan}, inplace=True)\n",
    "    tranc.age.replace({118: np.nan}, inplace=True)\n",
    "    tranc['cum_amount'] = tranc.groupby('person').amount.cumsum()\n",
    "    tranc.event = pd.Categorical(tranc.event, categories=['offer received', 'offer viewed', 'offer completed', 'transaction'], ordered=True)\n",
    "    tranc['offer_id'] = tranc.person + tranc.id.astype(str)\n",
    "    tranc = tranc[['offer_id', 'person', 'event', 'time', 'age', 'income', 'signed_up', 'F', 'M', 'O',\n",
    "               'amount', 'id', 'rewarded', 'difficulty', 'reward', 'duration', 'mobile', 'web', \n",
    "               'social', 'bogo', 'discount', 'informational', 'cum_amount']]\n",
    "    tranc['offer_multi'] = tranc.offer_id + tranc.event.astype(str)\n",
    "    tranc['offer_multi_correction'] = tranc.groupby('offer_multi').offer_id.apply(lambda n: n + (np.arange(len(n))+1).astype(str))\n",
    "    tranc.offer_id = tranc.offer_multi_correction\n",
    "    tranc.drop(['offer_multi', 'offer_multi_correction'], axis=1, inplace=True)\n",
    "    tranc['joined'] = (tranc.signed_up - tranc.signed_up.max()).dt.days\n",
    "    tranc = tranc.join(pd.get_dummies(tranc.event))\n",
    "    tranc['id'] = pd.Categorical(tranc.id, categories=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', '0'], ordered=True)\n",
    "    \n",
    "    if save:\n",
    "        try:\n",
    "            dirName='../../data/interim'\n",
    "            os.mkdir(dirName)\n",
    "            print(\"Directory \" , dirName ,  \" Created \") \n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        \n",
    "        #tranc.to_csv(dirName + '/tranc.csv', index=False)\n",
    "        #tranc.to_pickle(dirName + '/tranc.pickle')\n",
    "        #print('saved as {}'.format(dirName + '/tranc.pickle'))\n",
    "        \n",
    "        joblib.dump(tranc, dirName + '/' + save, compress=True)\n",
    "        print('saved as {}'.format(dirName + '/' + save)) \n",
    "    \n",
    "    return tranc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qCzUCbxqmHEI"
   },
   "outputs": [],
   "source": [
    "tranc = wrangle_portfolio(portfolio, profile, transcript, save='tranc.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHSSX7domHEJ"
   },
   "outputs": [],
   "source": [
    "tranc"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1. Data_wrangling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
